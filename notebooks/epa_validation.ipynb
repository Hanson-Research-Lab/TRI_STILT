{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitstiltvenvd0b5b9a6265a460294244206ccd6e7b1",
   "display_name": "Python 3.7.7 64-bit ('stilt': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRI Modeling Validation\n",
    "\n",
    "gl\n",
    "<br>\n",
    "09.29.20\n",
    "\n",
    "- only three sensors in reasonable proximity for 90-99 and all lead\n",
    "- want to check the 2000-2018 for potential matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import geopandas as gpd \n",
    "import contextily as ctx\n",
    "import matplotlib.pyplot as plt\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "import glob\n",
    "import click\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr \n",
    "from shapely.geometry import Point\n",
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling the sensor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total TRI releases 1990-2018: 2231\n\nTotal number of EPA monitors recording after 1990: 88\n\nEPA tracked chemicals: \nETHYLBENZENE, STYRENE, 1,2-DIBROMOETHANE, 1,3-BUTADIENE, 1,2-DICHLOROETHANE, METHYL ISOBUTYL KETONE, TETRACHLOROETHYLENE, FORMALDEHYDE, CHLOROFORM, BENZENE, LEAD, NICKEL, CADMIUM, COBALT, DICHLOROMETHANE, ETHYLENE OXIDE, TRICHLOROETHYLENE, NAPHTHALENE, CUMENE\n\nUnique EPA Sensor Locations: 12\n"
    }
   ],
   "source": [
    "#Load in TRI data from 1990 - 2018 to look for relevant sensors (run with makefile commands in processed/data_origin.txt)\n",
    "TRI_base_process_90_18_nopubchem_df = pd.read_csv('/home/boogie2/Hanson_Lab/TRI_STILT/data/processed/TRI_base_process_90_18_nopubchem.csv')\n",
    "TRI_base_process_90_18_nopubchem_df = TRI_base_process_90_18_nopubchem_df.drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "#While there may be duplicates in the data, we don't need them for this analysis\n",
    "TRI_base_process_90_18_nopubchem_df = TRI_base_process_90_18_nopubchem_df.drop_duplicates()\n",
    "\n",
    "#Load in EPA monitors data\n",
    "EPA_mon = pd.read_csv('/home/boogie2/Hanson_Lab/TRI_STILT/data/validation/TRIChemicals_Monitors.csv')\n",
    "\n",
    "#Interested in the monitors from 1990 to 2018\n",
    "valid_monitors = EPA_mon[(EPA_mon['first_year']>=1990)]\n",
    "\n",
    "print('Total TRI releases 1990-2018: {0}'.format(TRI_base_process_90_18_nopubchem_df.shape[0]))\n",
    "print('\\nTotal number of EPA monitors recording after 1990: {0}'.format(valid_monitors.shape[0]))\n",
    "print('\\nEPA tracked chemicals: ')\n",
    "print(*valid_monitors['chemicalname'].drop_duplicates().values, sep = \", \")\n",
    "print('\\nUnique EPA Sensor Locations: {}'.format(valid_monitors.drop_duplicates(subset= ['latitude','longitude']).shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First need to sort the EPA sensors by ID to see which chemicals are at which facilities\n",
    "valid_monitors['casnumber'] = valid_monitors['casnumber'].str.replace('-','')\n",
    "epa_sensors_locs = valid_monitors.groupby(['latitude','longitude'])['casnumber'].apply(list)\n",
    "epa_sensors_locs = epa_sensors_locs.reset_index()\n",
    "\n",
    "#Gather the CAS numbers for the unique chemicals (EPA sensors)\n",
    "unique_cas = epa_sensors_locs['casnumber'].to_list()\n",
    "unique_cas = [item for sublist in unique_cas for item in sublist]\n",
    "unique_cas =list(dict.fromkeys(unique_cas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First calculate the TRI emitters which are closest to the origin source AND have chemicals within the list of TRI emitters \n",
    "a= []\n",
    "\n",
    "for idx in range(epa_sensors_locs.shape[0]):\n",
    "    locs = TRI_base_process_90_18_nopubchem_df\n",
    "    temp =epa_sensors_locs.iloc[idx] # This is EPA monitor\n",
    "\n",
    "    #Should be using Haversin because of the rounded nature of the earth\n",
    "    locs['haversine_distance_km']=locs.apply(lambda row : haversine(row['LONGITUDE'],row['LATITUDE'],temp['longitude'],temp['latitude']), axis = 1)\n",
    "\n",
    "    #In order to add multiple entries per each - I think I will just change the iloc here to a boolean based upon distance\n",
    "    matches = locs[locs['CAS#/COMPOUNDID'].isin(epa_sensors_locs['casnumber'].iloc[idx])]\n",
    "    matches = matches[matches.haversine_distance_km<50]\n",
    "    a.append(matches)\n",
    "\n",
    "nearest_ls = pd.concat([epa_sensors_locs.reset_index(),pd.DataFrame(a).reset_index()],axis=1)\n",
    "nearest_ls = nearest_ls.drop(columns=['index'])\n",
    "\n",
    "#Remove any sensors which have no sensors nearby\n",
    "nearest_ls = nearest_ls[nearest_ls[0].apply(lambda x: x.empty)==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the list of dataframes into one large dataframe\n",
    "temp_list = []\n",
    "for rows in range(nearest_ls.shape[0]):\n",
    "    temp_df = nearest_ls[0].iloc[rows]\n",
    "    temp_df['EPA_lat'] = nearest_ls['latitude'].iloc[rows]\n",
    "    temp_df['EPA_long'] = nearest_ls['longitude'].iloc[rows]\n",
    "    temp_df['casnumber'] = str(nearest_ls['casnumber'].iloc[rows])\n",
    "    temp_list.append(temp_df)\n",
    "\n",
    "EPA_TRI_merge_by_nearest_sensor = pd.concat(temp_list)\n",
    "EPA_TRI_merge_by_nearest_sensor = EPA_TRI_merge_by_nearest_sensor.dropna(subset=['Group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       EPA_lat  EPA_long   LATITUDE   LONGITUDE CHEMICAL            TRIFD  \\\n0    37.198299 -113.1506  37.037627 -113.544195     LEAD  84770STKRP1843E   \n1    37.198299 -113.1506  37.043001 -113.532888     LEAD  8479WSNRCC1825E   \n2    37.198299 -113.1506  37.120370 -113.556790   NICKEL  84770STGRG1301E   \n3    37.198299 -113.1506  37.169211 -113.423103     LEAD  8473WSNRCC155NR   \n4    37.459080 -113.2251  37.120370 -113.556790   NICKEL  84770STGRG1301E   \n..         ...       ...        ...         ...      ...              ...   \n593  41.842648 -111.8522  41.763580 -111.860270     LEAD  84321NVRNC1073W   \n594  41.842648 -111.8522  41.771330 -111.848860     LEAD  8432WGNVRC2151N   \n595  41.842648 -111.8522  41.882500 -112.196400  CADMIUM  84330NCRST7285W   \n596  41.842648 -111.8522  41.882500 -112.196400     LEAD  84330NCRST7285W   \n597  41.842648 -111.8522  41.882500 -112.196400   NICKEL  84330NCRST7285W   \n\n     haversine_distance_km                                               YEAR  \n0                39.205851         [2012, 2013, 2014, 2015, 2016, 2017, 2018]  \n1                38.040146                                             [2018]  \n2                37.023942                     [2011, 2012, 2013, 2014, 2015]  \n3                24.356513                                             [2018]  \n4                47.743947                     [2011, 2012, 2013, 2014, 2015]  \n..                     ...                                                ...  \n593               8.817370  [2010, 2011, 2012, 2013, 2014, 2015, 2016, 201...  \n594               7.935030                                             [2018]  \n595              28.846324                                       [1990, 1991]  \n596              28.846324                           [1990, 1991, 1992, 1993]  \n597              28.846324                                             [1993]  \n\n[598 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EPA_lat</th>\n      <th>EPA_long</th>\n      <th>LATITUDE</th>\n      <th>LONGITUDE</th>\n      <th>CHEMICAL</th>\n      <th>TRIFD</th>\n      <th>haversine_distance_km</th>\n      <th>YEAR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>37.198299</td>\n      <td>-113.1506</td>\n      <td>37.037627</td>\n      <td>-113.544195</td>\n      <td>LEAD</td>\n      <td>84770STKRP1843E</td>\n      <td>39.205851</td>\n      <td>[2012, 2013, 2014, 2015, 2016, 2017, 2018]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>37.198299</td>\n      <td>-113.1506</td>\n      <td>37.043001</td>\n      <td>-113.532888</td>\n      <td>LEAD</td>\n      <td>8479WSNRCC1825E</td>\n      <td>38.040146</td>\n      <td>[2018]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>37.198299</td>\n      <td>-113.1506</td>\n      <td>37.120370</td>\n      <td>-113.556790</td>\n      <td>NICKEL</td>\n      <td>84770STGRG1301E</td>\n      <td>37.023942</td>\n      <td>[2011, 2012, 2013, 2014, 2015]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>37.198299</td>\n      <td>-113.1506</td>\n      <td>37.169211</td>\n      <td>-113.423103</td>\n      <td>LEAD</td>\n      <td>8473WSNRCC155NR</td>\n      <td>24.356513</td>\n      <td>[2018]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>37.459080</td>\n      <td>-113.2251</td>\n      <td>37.120370</td>\n      <td>-113.556790</td>\n      <td>NICKEL</td>\n      <td>84770STGRG1301E</td>\n      <td>47.743947</td>\n      <td>[2011, 2012, 2013, 2014, 2015]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>41.842648</td>\n      <td>-111.8522</td>\n      <td>41.763580</td>\n      <td>-111.860270</td>\n      <td>LEAD</td>\n      <td>84321NVRNC1073W</td>\n      <td>8.817370</td>\n      <td>[2010, 2011, 2012, 2013, 2014, 2015, 2016, 201...</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>41.842648</td>\n      <td>-111.8522</td>\n      <td>41.771330</td>\n      <td>-111.848860</td>\n      <td>LEAD</td>\n      <td>8432WGNVRC2151N</td>\n      <td>7.935030</td>\n      <td>[2018]</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>41.842648</td>\n      <td>-111.8522</td>\n      <td>41.882500</td>\n      <td>-112.196400</td>\n      <td>CADMIUM</td>\n      <td>84330NCRST7285W</td>\n      <td>28.846324</td>\n      <td>[1990, 1991]</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>41.842648</td>\n      <td>-111.8522</td>\n      <td>41.882500</td>\n      <td>-112.196400</td>\n      <td>LEAD</td>\n      <td>84330NCRST7285W</td>\n      <td>28.846324</td>\n      <td>[1990, 1991, 1992, 1993]</td>\n    </tr>\n    <tr>\n      <th>597</th>\n      <td>41.842648</td>\n      <td>-111.8522</td>\n      <td>41.882500</td>\n      <td>-112.196400</td>\n      <td>NICKEL</td>\n      <td>84330NCRST7285W</td>\n      <td>28.846324</td>\n      <td>[1993]</td>\n    </tr>\n  </tbody>\n</table>\n<p>598 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 335
    }
   ],
   "source": [
    "#Cleaning up the dataframes a bit \n",
    "EPA_TRI_merge_by_nearest_sensor = EPA_TRI_merge_by_nearest_sensor[['FRSID',\n",
    "                                                                    'YEAR',\n",
    "                                                                    'TRIFD',\n",
    "                                                                    'CAS#/COMPOUNDID',\n",
    "                                                                    'CHEMICAL',\n",
    "                                                                    'LATITUDE',\n",
    "                                                                    'LONGITUDE',\n",
    "                                                                    'EPA_lat',\n",
    "                                                                    'EPA_long',\n",
    "                                                                    'casnumber',\n",
    "                                                                    'haversine_distance_km']]\n",
    "\n",
    "\n",
    "# Expanding the output so each EPA lat/long ~ sensor ~ showcases the nearest TRI release with distance and years produced\n",
    "EPA_TRI_merge_by_nearest_sensor_loc_agg = EPA_TRI_merge_by_nearest_sensor.groupby(['EPA_lat','EPA_long','LATITUDE','LONGITUDE','CHEMICAL','TRIFD','haversine_distance_km'])['YEAR'].apply(list).reset_index()\n",
    "EPA_TRI_merge_by_nearest_sensor_loc_agg = pd.DataFrame(EPA_TRI_merge_by_nearest_sensor_loc_agg)\n",
    "EPA_TRI_merge_by_nearest_sensor_loc_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the Data: \n",
    "EPA_TRI_merge_by_nearest_sensor_loc_agg.to_csv('/home/boogie2/Hanson_Lab/TRI_STILT/data/validation/EPA_validation_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ATTEMPTING TO FIGURE OUT WHY THE JOIN BETWEEN THE ORIGINAL TRI DATA DOES NOT FULLY MATCH\n",
    "test = pd.read_csv('/home/boogie2/Hanson_Lab/TRI_STILT/data/validation/EPA_validation_100.csv')[['TRIFD','CHEMICAL','LATITUDE','LONGITUDE']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So it seems there may be an error here. It is partially due to the rounded nature of the values being exported. But all cannot be found by the merge which is really weird. \n",
    "test['LATITUDE']=test['LATITUDE'].round(5)\n",
    "test['LONGITUDE']=test['LONGITUDE'].round(5)\n",
    "\n",
    "\n",
    "tri_9_18_df['LATITUDE']=tri_9_18_df['LATITUDE'].round(5)\n",
    "tri_9_18_df['LONGITUDE']=tri_9_18_df['LONGITUDE'].round(5)\n",
    "\n",
    "# SO YOU MUST BE VERY CAREFUL WITH THE LAT AND LONG BECAUSE THEY CAN BE UNSTANDARDIZED!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    index            TRIFD CHEMICAL  LATITUDE  LONGITUDE\n32     34  8408WWSTJR5792W     LEAD  40.57516 -112.02899",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>TRIFD</th>\n      <th>CHEMICAL</th>\n      <th>LATITUDE</th>\n      <th>LONGITUDE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>32</th>\n      <td>34</td>\n      <td>8408WWSTJR5792W</td>\n      <td>LEAD</td>\n      <td>40.57516</td>\n      <td>-112.02899</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 360
    }
   ],
   "source": [
    "lat_lon_test = test.merge(tri_9_18_df[['TRIFD','CHEMICAL','LATITUDE','LONGITUDE']].drop_duplicates()).sort_values(by='index')\n",
    "\n",
    "\n",
    "#ARE THE SHAPES THE SAME? \n",
    "print('THE SHAPE OF EXPORTED DATA: ' + str(test.shape))\n",
    "print('THE SHAPE OF MERGED DATA: ' + str(lat_lon_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    index            TRIFD CHEMICAL  LATITUDE  LONGITUDE\n32     34  8408WWSTJR5792W     LEAD  40.57516 -112.02899",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>TRIFD</th>\n      <th>CHEMICAL</th>\n      <th>LATITUDE</th>\n      <th>LONGITUDE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>32</th>\n      <td>34</td>\n      <td>8408WWSTJR5792W</td>\n      <td>LEAD</td>\n      <td>40.57516</td>\n      <td>-112.02899</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 365
    }
   ],
   "source": [
    "#Which is causing the issue\n",
    "test[~test['index'].isin(lat_lon_test['index'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      YEAR CHEMICAL  LATITUDE  LONGITUDE\n1151  2016     LEAD  40.57517 -112.02899\n1179  2017     LEAD  40.57517 -112.02899",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>YEAR</th>\n      <th>CHEMICAL</th>\n      <th>LATITUDE</th>\n      <th>LONGITUDE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1151</th>\n      <td>2016</td>\n      <td>LEAD</td>\n      <td>40.57517</td>\n      <td>-112.02899</td>\n    </tr>\n    <tr>\n      <th>1179</th>\n      <td>2017</td>\n      <td>LEAD</td>\n      <td>40.57517</td>\n      <td>-112.02899</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 356
    }
   ],
   "source": [
    "#Yes. But why are these being rounded differently???\n",
    "tri_9_18_df[(tri_9_18_df['TRIFD']=='8408WWSTJR5792W')][['YEAR','CHEMICAL','LATITUDE','LONGITUDE']]"
   ]
  },
  {
   "source": [
    "# Modeling EPA Validation Sensors\n",
    "\n",
    "Joemy merged all EPA sensor data with TRI releases so we can start to validate the model. \n",
    "\n",
    "09.30.20 \n",
    "<br>\n",
    "\n",
    "Herein, I explore the possibility of taking the TRI validation set, running a sample of 100 stilt models, then rejoining back the EPA validation data to see how the concentrations differ. Talking with Ben and Derick showcased that it is probably best to focus on a specific chemical, most likely lead, as it is relatively inert. This code is an **exploration** in results and should not be consdered refined or tested. \n",
    "\n",
    "THE ISSUE ABOVE WILL NEED TO BE FIXED FOR THIS TO WORK PROPERLY"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "TRI_validation_df = pd.read_csv('/home/boogie2/Hanson_Lab/TRI_STILT/data/validation/TRI_ValidationSet.csv')\n",
    "TRI_validation_df['sample_dt'] = pd.to_datetime(TRI_validation_df['sample_dt'],format='%m-%d-%Y')\n",
    "\n",
    "#Collecting only those simulations through 2014 because that is where I have NARR data through\n",
    "tri_valid_2014 = TRI_validation_df[TRI_validation_df.year<=2014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_9_18_df = pd.read_csv('/home/boogie2/Hanson_Lab/TRI_STILT/data/processed/TRI_base_process_90_18_nopubchem.csv').drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(2214, 5)"
     },
     "metadata": {},
     "execution_count": 286
    }
   ],
   "source": [
    "#There is a weird discrepency between what is expected in overlap. Between the original TRI data and this validation set. When merged together, only 73/624 tri_validation monitors overlap with those found in the original TRI dataset\n",
    "a = tri_9_18_df[['YEAR','TRIFD','CHEMICAL','LATITUDE','LONGITUDE']].drop_duplicates()\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index([&#39;monitor_group&#39;, &#39;parametername&#39;, &#39;monitorid&#39;, &#39;year&#39;, &#39;sampleduration&#39;,\n       &#39;latitude&#39;, &#39;longitude&#39;, &#39;casnumber&#39;, &#39;trifd&#39;, &#39;cas_no&#39;, &#39;haps_unit&#39;,\n       &#39;haps_conc&#39;, &#39;chemical&#39;, &#39;group&#39;, &#39;frsid&#39;, &#39;facilityname&#39;, &#39;city&#39;,\n       &#39;county&#39;, &#39;st&#39;, &#39;zip&#39;, &#39;tri_lat&#39;, &#39;tri_lon&#39;, &#39;cascompoundid&#39;, &#39;metal&#39;,\n       &#39;carcinogen&#39;, &#39;stackheight&#39;, &#39;stackvelocity&#39;, &#39;stackdiameter&#39;,\n       &#39;stackheightsource&#39;, &#39;stackvelocitysource&#39;, &#39;stackdiametersource&#39;,\n       &#39;sample_dt&#39;],\n      dtype=&#39;object&#39;)"
     },
     "metadata": {},
     "execution_count": 289
    }
   ],
   "source": [
    "tri_valid_2014.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(624, 5)"
     },
     "metadata": {},
     "execution_count": 287
    }
   ],
   "source": [
    "b = tri_valid_2014[['year','trifd','chemical','tri_lat','tri_lon']].drop_duplicates()\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    YEAR            TRIFD      CHEMICAL  LATITUDE  LONGITUDE  year  \\\n0   1996  84087CRYSN2355S        CUMENE  40.86631 -111.91187  1996   \n1   2010  84087CRYSN2355S        CUMENE  40.86631 -111.91187  2010   \n2   2010  84087CRYSN2355S   NAPHTHALENE  40.86631 -111.91187  2010   \n3   2011  84087CRYSN2355S   NAPHTHALENE  40.86631 -111.91187  2011   \n4   2012  84087CRYSN2355S   NAPHTHALENE  40.86631 -111.91187  2012   \n..   ...              ...           ...       ...        ...   ...   \n68  2011  84087CRYSN2355S  ETHYLBENZENE  40.86631 -111.91187  2011   \n69  2012  84087CRYSN2355S  ETHYLBENZENE  40.86631 -111.91187  2012   \n70  2013  84660TLFLX1800N  ETHYLBENZENE  40.13290 -111.66150  2013   \n71  2013  84087CRYSN2355S  ETHYLBENZENE  40.86631 -111.91187  2013   \n72  2014  84087CRYSN2355S  ETHYLBENZENE  40.86631 -111.91187  2014   \n\n              trifd      chemical   tri_lat    tri_lon  \n0   84087CRYSN2355S        CUMENE  40.86631 -111.91187  \n1   84087CRYSN2355S        CUMENE  40.86631 -111.91187  \n2   84087CRYSN2355S   NAPHTHALENE  40.86631 -111.91187  \n3   84087CRYSN2355S   NAPHTHALENE  40.86631 -111.91187  \n4   84087CRYSN2355S   NAPHTHALENE  40.86631 -111.91187  \n..              ...           ...       ...        ...  \n68  84087CRYSN2355S  ETHYLBENZENE  40.86631 -111.91187  \n69  84087CRYSN2355S  ETHYLBENZENE  40.86631 -111.91187  \n70  84660TLFLX1800N  ETHYLBENZENE  40.13290 -111.66150  \n71  84087CRYSN2355S  ETHYLBENZENE  40.86631 -111.91187  \n72  84087CRYSN2355S  ETHYLBENZENE  40.86631 -111.91187  \n\n[73 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>YEAR</th>\n      <th>TRIFD</th>\n      <th>CHEMICAL</th>\n      <th>LATITUDE</th>\n      <th>LONGITUDE</th>\n      <th>year</th>\n      <th>trifd</th>\n      <th>chemical</th>\n      <th>tri_lat</th>\n      <th>tri_lon</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1996</td>\n      <td>84087CRYSN2355S</td>\n      <td>CUMENE</td>\n      <td>40.86631</td>\n      <td>-111.91187</td>\n      <td>1996</td>\n      <td>84087CRYSN2355S</td>\n      <td>CUMENE</td>\n      <td>40.86631</td>\n      <td>-111.91187</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2010</td>\n      <td>84087CRYSN2355S</td>\n      <td>CUMENE</td>\n      <td>40.86631</td>\n      <td>-111.91187</td>\n      <td>2010</td>\n      <td>84087CRYSN2355S</td>\n      <td>CUMENE</td>\n      <td>40.86631</td>\n      <td>-111.91187</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2010</td>\n      <td>84087CRYSN2355S</td>\n      <td>NAPHTHALENE</td>\n      <td>40.86631</td>\n      <td>-111.91187</td>\n      <td>2010</td>\n      <td>84087CRYSN2355S</td>\n      <td>NAPHTHALENE</td>\n      <td>40.86631</td>\n      <td>-111.91187</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2011</td>\n      <td>84087CRYSN2355S</td>\n      <td>NAPHTHALENE</td>\n      <td>40.86631</td>\n      <td>-111.91187</td>\n      <td>2011</td>\n      <td>84087CRYSN2355S</td>\n      <td>NAPHTHALENE</td>\n      <td>40.86631</td>\n      <td>-111.91187</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2012</td>\n      <td>84087CRYSN2355S</td>\n      <td>NAPHTHALENE</td>\n      <td>40.86631</td>\n      <td>-111.91187</td>\n      <td>2012</td>\n      <td>84087CRYSN2355S</td>\n      <td>NAPHTHALENE</td>\n      <td>40.86631</td>\n      <td>-111.91187</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>2011</td>\n      <td>84087CRYSN2355S</td>\n      <td>ETHYLBENZENE</td>\n      <td>40.86631</td>\n      <td>-111.91187</td>\n      <td>2011</td>\n      <td>84087CRYSN2355S</td>\n      <td>ETHYLBENZENE</td>\n      <td>40.86631</td>\n      <td>-111.91187</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>2012</td>\n      <td>84087CRYSN2355S</td>\n      <td>ETHYLBENZENE</td>\n      <td>40.86631</td>\n      <td>-111.91187</td>\n      <td>2012</td>\n      <td>84087CRYSN2355S</td>\n      <td>ETHYLBENZENE</td>\n      <td>40.86631</td>\n      <td>-111.91187</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>2013</td>\n      <td>84660TLFLX1800N</td>\n      <td>ETHYLBENZENE</td>\n      <td>40.13290</td>\n      <td>-111.66150</td>\n      <td>2013</td>\n      <td>84660TLFLX1800N</td>\n      <td>ETHYLBENZENE</td>\n      <td>40.13290</td>\n      <td>-111.66150</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>2013</td>\n      <td>84087CRYSN2355S</td>\n      <td>ETHYLBENZENE</td>\n      <td>40.86631</td>\n      <td>-111.91187</td>\n      <td>2013</td>\n      <td>84087CRYSN2355S</td>\n      <td>ETHYLBENZENE</td>\n      <td>40.86631</td>\n      <td>-111.91187</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>2014</td>\n      <td>84087CRYSN2355S</td>\n      <td>ETHYLBENZENE</td>\n      <td>40.86631</td>\n      <td>-111.91187</td>\n      <td>2014</td>\n      <td>84087CRYSN2355S</td>\n      <td>ETHYLBENZENE</td>\n      <td>40.86631</td>\n      <td>-111.91187</td>\n    </tr>\n  </tbody>\n</table>\n<p>73 rows × 10 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 285
    }
   ],
   "source": [
    "a.merge(b, how='inner',right_on= ['year','trifd','chemical','tri_lat','tri_lon'],left_on=['YEAR','TRIFD','CHEMICAL','LATITUDE','LONGITUDE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing for STILT Simulation\n",
    "stilt_df = tri_valid_2014[['tri_lat','tri_lon','stackheight','sample_dt']].drop_duplicates()\n",
    "stilt_df.columns = ['lati','long','zagl','run_times']\n",
    "\n",
    "#Save to csv file\n",
    "stilt_df.to_csv('/home/boogie2/Hanson_Lab/TRI_STILT/data/validation/092920_epa_valid_2014.csv',index=False)\n",
    "\n",
    "#Ran a subsample of the original (select within the following R file)\n",
    "    #Edited ./src/validation/092920_epa_validation.r to only sample 100 releases (CHPC disk issues)\n"
   ]
  },
  {
   "source": [
    "### Processing the Subsample of Validation Data (no script built yet)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nc_open(path):\n",
    "    \"\"\"\n",
    "    A function to open netcdf4 files. Requires xarray\n",
    "    ===\n",
    "    Input:\n",
    "    path - path to the cdf file\n",
    "\n",
    "    Output: \n",
    "    df - converted cdf file to dataframe object\n",
    "    \"\"\"\n",
    "    df = xr.open_dataarray(path)\n",
    "    return df.to_dataframe().reset_index()\n",
    "\n",
    "def stilt_netcdf_to_gdf(stilt_df, threshold):\n",
    "    '''Takes a stilt footprint, filters based upon a threshold and averages the simulation \n",
    "\n",
    "    Input:\n",
    "    ----------  \n",
    "    stilt_df - an output coming from nc_open, based upon netcdf to pandas conversion\n",
    "    threshold - a value for filtering - if null no filtering is performed on the data. \n",
    "    epsg - coordinate selection for mapping\n",
    "\n",
    "    Returns:\n",
    "    sim_avg: a geodataframe of the average non-log_conc per the simulation run (48 hr with current setup) transformed to points for comparison\n",
    "    '''  \n",
    "    if threshold != None:\n",
    "        stilt_df = stilt_df[stilt_df.foot>threshold] \n",
    "    \n",
    "    sim_avg = stilt_df.groupby(['lat','lon']).agg({'foot':'mean'}).reset_index()\n",
    "    return sim_avg\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First need to create a csv file of all the epa validation info\n",
    "\n",
    "#Then need to merge on the TRI information retaining only those trifd's which are present within tri_valid_2014\n",
    "\n",
    "#Then calculate the release per the year\n",
    "\n",
    "#Check to see if there is a grid cell match "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_locations_df = tri_valid_2014[['latitude','longitude']].drop_duplicates()\n",
    "epa_locations_df = epa_locations_df.rename(columns={'latitude':'epa_latitude','longitude':'epa_longitude'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the grid cells which are closest\n",
    "lat_ls = []\n",
    "lon_ls = []\n",
    "\n",
    "for rows in range(epa_locations_df.shape[0]):\n",
    "    temp_lat = epa_locations_df.latitude.iloc[rows]\n",
    "    temp_lon = epa_locations_df.longitude.iloc[rows]\n",
    "\n",
    "    stilt_sim_gdf['dist'] = stilt_sim_gdf.apply(lambda row : haversine(row['lon'],row['lat'],temp_lon,temp_lat), axis = 1)\n",
    "    lat_ls.append(stilt_sim_gdf.iloc[stilt_sim_gdf['dist'].idxmin()].lat)\n",
    "    lon_ls.append(stilt_sim_gdf.iloc[stilt_sim_gdf['dist'].idxmin()].lon)\n",
    "    \n",
    "    stilt_sim_gdf = stilt_sim_gdf.drop(columns='dist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_locations_df['nearest_stilt_grid_lat'] = lat_ls\n",
    "epa_locations_df['nearest_stilt_grid_lon'] = lon_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "stilt_filepath= '/home/boogie2/Hanson_Lab/TRI_STILT/data/processed/stilt_output/netcdf/092920_epa_valid_2014'\n",
    "\n",
    "#Load the Mapping Files\n",
    "temp_data_list = []\n",
    "counter = 0\n",
    "# Gather Chemical information based upon the id_mappings\n",
    "for files in glob.glob(stilt_filepath + '/*.nc'):\n",
    "\n",
    "    #Extract information from the data label\n",
    "    filename = files.split('/')[-1].split('.nc')[0]\n",
    "    date = pd.to_datetime(int(filename.split('_')[0][0:8]),format='%Y%m%d')\n",
    "    longi = float(filename.split('_')[1])\n",
    "    lati = float(filename.split('_')[2])\n",
    "    zagl = float(filename.split('_')[3])\n",
    "\n",
    "    stilt_sim_gdf = nc_open(files)\n",
    "    stilt_sim_gdf = stilt_netcdf_to_gdf(stilt_sim_gdf,None)\n",
    "    \n",
    "    points_of_interest = stilt_sim_gdf.merge(epa_locations_df, left_on=['lat','lon'],how='inner', right_on=['nearest_stilt_grid_lat','nearest_stilt_grid_lon']).drop(columns = ['nearest_stilt_grid_lat','nearest_stilt_grid_lon'])\n",
    "    \n",
    "    points_of_interest['filename'] = filename\n",
    "    points_of_interest['date'] = date\n",
    "    points_of_interest['zagl'] = zagl\n",
    "    points_of_interest['year'] = pd.DatetimeIndex(points_of_interest['date']).year\n",
    "    points_of_interest['tri_source_lat'] = lati\n",
    "    points_of_interest['tri_source_lon'] = longi\n",
    "\n",
    "    #62/100 have a value over zero at the grid cell closest to the EPA monitor. Let's collect all of those and put them into a dataframe\n",
    "    if points_of_interest['foot'].sum()>0:\n",
    "        temp_data_list.append(points_of_interest)\n",
    "\n",
    "    \n",
    "#For those that have positive values we need to add to a list then merge with the original TRI data\n",
    "stilt_epa_df = pd.concat(temp_data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the TRI info\n",
    "tri_9_18_df = pd.read_csv('/home/boogie2/Hanson_Lab/TRI_STILT/data/processed/TRI_base_process_90_18_nopubchem.csv').drop(columns=['Unnamed: 0'])\n",
    "\n",
    "#This separates fugitive and stack releases - setting the stack height of the release for fugitive releases to 0\n",
    "fug = tri_9_18_df[tri_9_18_df['51-FUGITIVEAIR']>0]\n",
    "fug['StackHeight']=0\n",
    "fug = fug.rename(columns = {'51-FUGITIVEAIR':'Release (lbs/year)'})\n",
    "fug = fug.drop(columns = ['52-STACKAIR'])\n",
    "\n",
    "stack = tri_9_18_df[tri_9_18_df['52-STACKAIR']>0]\n",
    "stack = stack.rename(columns = {'52-STACKAIR':'Release (lbs/year)'})\n",
    "stack = stack.drop(columns = ['51-FUGITIVEAIR'])\n",
    "\n",
    "#Concatenate the results together\n",
    "tri_9_18_df = pd.concat([stack,fug])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There is an issue here not picking matching to all stilt sites\n",
    "tri_9_18_df['StackHeight'] = tri_9_18_df['StackHeight'].round(2)\n",
    "tri_9_18_df['LATITUDE'] = tri_9_18_df['LATITUDE'].round(6)\n",
    "tri_9_18_df['LONGITUDE'] = tri_9_18_df['LONGITUDE'].round(6)\n",
    "\n",
    "stilt_epa_df['zagl'] = stilt_epa_df['zagl'].round(2)\n",
    "stilt_epa_df['tri_source_lat'] = stilt_epa_df['tri_source_lat'].round(6)\n",
    "stilt_epa_df['tri_source_lon'] = stilt_epa_df['tri_source_lon'].round(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "stilt_tri_df =stilt_epa_df.merge(tri_9_18_df,how='inner',left_on =['tri_source_lat','tri_source_lon','zagl','year'],right_on=['LATITUDE','LONGITUDE','StackHeight','YEAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_stilt_tri_df = tri_valid_2014.merge(stilt_tri_df,how='inner', left_on=['trifd','cas_no','sample_dt','latitude','longitude'],right_on=['TRIFD','CAS#/COMPOUNDID','date','epa_latitude','epa_longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Modeling EPA Validation Sensors: Proof of Concept"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         monitorid    year      latitude     longitude    cas_no   haps_conc  \\\ncount        342.0   342.0  3.420000e+02  3.420000e+02     342.0  342.000000   \nmean   490110004.0  2010.0  4.090290e+01 -1.118845e+02  100425.0    0.233781   \nstd            0.0     0.0  7.115838e-15  1.423168e-14       0.0    0.672109   \nmin    490110004.0  2010.0  4.090290e+01 -1.118845e+02  100425.0    0.007000   \n25%    490110004.0  2010.0  4.090290e+01 -1.118845e+02  100425.0    0.013000   \n50%    490110004.0  2010.0  4.090290e+01 -1.118845e+02  100425.0    0.079000   \n75%    490110004.0  2010.0  4.090290e+01 -1.118845e+02  100425.0    0.139500   \nmax    490110004.0  2010.0  4.090290e+01 -1.118845e+02  100425.0    4.630000   \n\n              frsid           zip     tri_lat     tri_lon  cascompoundid  \\\ncount  3.420000e+02  3.420000e+02  342.000000  342.000000          342.0   \nmean   1.100081e+11  1.402638e+08   40.850004 -112.117043       100425.0   \nstd    1.407497e+07  3.139106e+08    0.126271    0.383589            0.0   \nmin    1.100005e+11  8.401600e+04   40.734402 -112.968100       100425.0   \n25%    1.100005e+11  8.402900e+04   40.742111 -112.033600       100425.0   \n50%    1.100008e+11  8.407050e+04   40.816246 -111.942320       100425.0   \n75%    1.100069e+11  8.410400e+04   40.886021 -111.911160       100425.0   \nmax    1.100391e+11  8.411623e+08   41.105000 -111.904760       100425.0   \n\n       stackheight  stackvelocity  stackdiameter  \ncount   342.000000     342.000000     342.000000  \nmean     14.766666       9.866667       0.766667  \nstd       9.667929       4.818032       0.335487  \nmin       7.700000       2.000000       0.300000  \n25%       9.400000       6.000000       0.600000  \n50%      10.050000      10.200000       0.700000  \n75%      15.800000      15.200000       0.900000  \nmax      35.599998      15.600000       1.400000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>monitorid</th>\n      <th>year</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>cas_no</th>\n      <th>haps_conc</th>\n      <th>frsid</th>\n      <th>zip</th>\n      <th>tri_lat</th>\n      <th>tri_lon</th>\n      <th>cascompoundid</th>\n      <th>stackheight</th>\n      <th>stackvelocity</th>\n      <th>stackdiameter</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>342.0</td>\n      <td>342.0</td>\n      <td>3.420000e+02</td>\n      <td>3.420000e+02</td>\n      <td>342.0</td>\n      <td>342.000000</td>\n      <td>3.420000e+02</td>\n      <td>3.420000e+02</td>\n      <td>342.000000</td>\n      <td>342.000000</td>\n      <td>342.0</td>\n      <td>342.000000</td>\n      <td>342.000000</td>\n      <td>342.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>490110004.0</td>\n      <td>2010.0</td>\n      <td>4.090290e+01</td>\n      <td>-1.118845e+02</td>\n      <td>100425.0</td>\n      <td>0.233781</td>\n      <td>1.100081e+11</td>\n      <td>1.402638e+08</td>\n      <td>40.850004</td>\n      <td>-112.117043</td>\n      <td>100425.0</td>\n      <td>14.766666</td>\n      <td>9.866667</td>\n      <td>0.766667</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>7.115838e-15</td>\n      <td>1.423168e-14</td>\n      <td>0.0</td>\n      <td>0.672109</td>\n      <td>1.407497e+07</td>\n      <td>3.139106e+08</td>\n      <td>0.126271</td>\n      <td>0.383589</td>\n      <td>0.0</td>\n      <td>9.667929</td>\n      <td>4.818032</td>\n      <td>0.335487</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>490110004.0</td>\n      <td>2010.0</td>\n      <td>4.090290e+01</td>\n      <td>-1.118845e+02</td>\n      <td>100425.0</td>\n      <td>0.007000</td>\n      <td>1.100005e+11</td>\n      <td>8.401600e+04</td>\n      <td>40.734402</td>\n      <td>-112.968100</td>\n      <td>100425.0</td>\n      <td>7.700000</td>\n      <td>2.000000</td>\n      <td>0.300000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>490110004.0</td>\n      <td>2010.0</td>\n      <td>4.090290e+01</td>\n      <td>-1.118845e+02</td>\n      <td>100425.0</td>\n      <td>0.013000</td>\n      <td>1.100005e+11</td>\n      <td>8.402900e+04</td>\n      <td>40.742111</td>\n      <td>-112.033600</td>\n      <td>100425.0</td>\n      <td>9.400000</td>\n      <td>6.000000</td>\n      <td>0.600000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>490110004.0</td>\n      <td>2010.0</td>\n      <td>4.090290e+01</td>\n      <td>-1.118845e+02</td>\n      <td>100425.0</td>\n      <td>0.079000</td>\n      <td>1.100008e+11</td>\n      <td>8.407050e+04</td>\n      <td>40.816246</td>\n      <td>-111.942320</td>\n      <td>100425.0</td>\n      <td>10.050000</td>\n      <td>10.200000</td>\n      <td>0.700000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>490110004.0</td>\n      <td>2010.0</td>\n      <td>4.090290e+01</td>\n      <td>-1.118845e+02</td>\n      <td>100425.0</td>\n      <td>0.139500</td>\n      <td>1.100069e+11</td>\n      <td>8.410400e+04</td>\n      <td>40.886021</td>\n      <td>-111.911160</td>\n      <td>100425.0</td>\n      <td>15.800000</td>\n      <td>15.200000</td>\n      <td>0.900000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>490110004.0</td>\n      <td>2010.0</td>\n      <td>4.090290e+01</td>\n      <td>-1.118845e+02</td>\n      <td>100425.0</td>\n      <td>4.630000</td>\n      <td>1.100391e+11</td>\n      <td>8.411623e+08</td>\n      <td>41.105000</td>\n      <td>-111.904760</td>\n      <td>100425.0</td>\n      <td>35.599998</td>\n      <td>15.600000</td>\n      <td>1.400000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "#So just for sake of efficiency - let's examine just a subset of the data (i choose styrene in 2010)\n",
    "styrene = TRI_validation_df[(TRI_validation_df.parametername == 'STYRENE') & (TRI_validation_df.year == 2010)]\n",
    "styrene.describe()"
   ]
  },
  {
   "source": [
    "Conclusions:\n",
    "\n",
    "1. Styrene data is available in the years 1996, 1999, 2010-17\n",
    "2. There is only a single EPA monitor (40.9029, -111.8845)  but four nearby releasing TRI sites\n",
    "3. Data is available on 57 dates "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trifd_of_interest = styrene['trifd'].drop_duplicates().to_list()\n",
    "chems_of_interest = styrene['cas_no'].drop_duplicates().to_list()\n",
    "\n",
    "#Let's filter the data for these trifd's of interest\n",
    "df = pd.read_csv('/home/boogie2/Hanson_Lab/TRI_STILT/data/processed/TRI_valid_2010_2010.csv').drop(columns = 'Unnamed: 0' )\n",
    "\n",
    "df['TRIFD'] = df.TRIFD.astype('string')\n",
    "entries_of_interest = df[(df.TRIFD.isin(trifd_of_interest)) & (df.CAS_No.isin(chems_of_interest))]\n",
    "\n",
    "#Now we should be ready to go\n",
    "entries_of_interest.to_csv('/home/boogie2/Hanson_Lab/TRI_STILT/data/processed/STYRENE_DEMO.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the TRI locations\n",
    "temp = pd.read_csv('/home/boogie2/Desktop/styrene_stilt_RUN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which dates do we want to model? (the current setup models on a everyday per year basis)\n",
    "dates_df = pd.DataFrame(sorted(styrene['sample_dt'].drop_duplicates()))\n",
    "dates_df['merge']=0\n",
    "temp['merge']=0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "styrene_run = temp.merge(dates_df).drop(columns =['merge','YEAR','id']).rename(columns={0:'run_times'})\n",
    "styrene_run.to_csv('styrene_run.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Run Simulations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's take a look: \n",
    "styrene_gdf = gpd.read_file('/home/boogie2/Hanson_Lab/TRI_STILT/data/processed/stilt_output/shapefile/092520_styrene')\n",
    "styrene_gdf['ss_date'] = pd.to_datetime(styrene_gdf['ss_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(38832, 15)"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "styrene_gdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_20100106 = styrene_gdf[styrene_gdf['ss_date']== '2010-01-06']\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "temp_20100106[temp_20100106.lbsperday>0.1].plot(column = 'lbsperday',ax = ax,alpha = 0.5,markersize=5)\n",
    "ctx.add_basemap(ax=ax)\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       TRI_source  TRI_sour_1\n0       40.742110 -111.958020\n14992   40.786392 -111.911163\n25782   41.105000 -112.033600\n28400   40.734400 -112.968100\n32116   40.886022 -111.904759\n32168   40.846100 -111.926620",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TRI_source</th>\n      <th>TRI_sour_1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40.742110</td>\n      <td>-111.958020</td>\n    </tr>\n    <tr>\n      <th>14992</th>\n      <td>40.786392</td>\n      <td>-111.911163</td>\n    </tr>\n    <tr>\n      <th>25782</th>\n      <td>41.105000</td>\n      <td>-112.033600</td>\n    </tr>\n    <tr>\n      <th>28400</th>\n      <td>40.734400</td>\n      <td>-112.968100</td>\n    </tr>\n    <tr>\n      <th>32116</th>\n      <td>40.886022</td>\n      <td>-111.904759</td>\n    </tr>\n    <tr>\n      <th>32168</th>\n      <td>40.846100</td>\n      <td>-111.926620</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "styrene_gdf[['TRI_source','TRI_sour_1']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          lat      lon      foot  lbsperday  id  TRI_source  TRI_sour_1  zagl  \\\n0      40.745 -111.955  0.084898   9.180184   0    40.74211  -111.95802   9.4   \n4      40.755 -111.955  0.073125   7.907112   0    40.74211  -111.95802   9.4   \n8      40.755 -111.945  0.069022   7.463464   0    40.74211  -111.95802   9.4   \n12     40.765 -111.945  0.147847  15.986922   0    40.74211  -111.95802   9.4   \n16     40.765 -111.935  0.003443   0.372280   0    40.74211  -111.95802   9.4   \n...       ...      ...       ...        ...  ..         ...         ...   ...   \n14972  40.945 -112.365  0.001034   0.111794   0    40.74211  -111.95802   9.4   \n14976  40.945 -112.355  0.001060   0.114596   0    40.74211  -111.95802   9.4   \n14980  40.945 -112.345  0.001065   0.115107   0    40.74211  -111.95802   9.4   \n14984  40.945 -112.335  0.001046   0.113152   0    40.74211  -111.95802   9.4   \n14988  40.945 -112.325  0.001009   0.109134   0    40.74211  -111.95802   9.4   \n\n      Chemical  Release (l  YEAR                                    ss_name  \\\n0      STYRENE     39468.0  2010  201001060000_-111.95802_40.74211_9.4_foot   \n4      STYRENE     39468.0  2010  201001060000_-111.95802_40.74211_9.4_foot   \n8      STYRENE     39468.0  2010  201001060000_-111.95802_40.74211_9.4_foot   \n12     STYRENE     39468.0  2010  201001060000_-111.95802_40.74211_9.4_foot   \n16     STYRENE     39468.0  2010  201001060000_-111.95802_40.74211_9.4_foot   \n...        ...         ...   ...                                        ...   \n14972  STYRENE     39468.0  2010  201001060000_-111.95802_40.74211_9.4_foot   \n14976  STYRENE     39468.0  2010  201001060000_-111.95802_40.74211_9.4_foot   \n14980  STYRENE     39468.0  2010  201001060000_-111.95802_40.74211_9.4_foot   \n14984  STYRENE     39468.0  2010  201001060000_-111.95802_40.74211_9.4_foot   \n14988  STYRENE     39468.0  2010  201001060000_-111.95802_40.74211_9.4_foot   \n\n                                                 ss_path    ss_date  \\\n0      data/processed/stilt_output/netcdf/092520_styr... 2010-01-06   \n4      data/processed/stilt_output/netcdf/092520_styr... 2010-01-06   \n8      data/processed/stilt_output/netcdf/092520_styr... 2010-01-06   \n12     data/processed/stilt_output/netcdf/092520_styr... 2010-01-06   \n16     data/processed/stilt_output/netcdf/092520_styr... 2010-01-06   \n...                                                  ...        ...   \n14972  data/processed/stilt_output/netcdf/092520_styr... 2010-01-06   \n14976  data/processed/stilt_output/netcdf/092520_styr... 2010-01-06   \n14980  data/processed/stilt_output/netcdf/092520_styr... 2010-01-06   \n14984  data/processed/stilt_output/netcdf/092520_styr... 2010-01-06   \n14988  data/processed/stilt_output/netcdf/092520_styr... 2010-01-06   \n\n                                geometry  \n0      POINT (-12462773.592 4974801.670)  \n4      POINT (-12462773.592 4976271.108)  \n8      POINT (-12461660.397 4976271.108)  \n12     POINT (-12461660.397 4977740.767)  \n16     POINT (-12460547.202 4977740.767)  \n...                                  ...  \n14972  POINT (-12508414.583 5004232.558)  \n14976  POINT (-12507301.388 5004232.558)  \n14980  POINT (-12506188.193 5004232.558)  \n14984  POINT (-12505074.998 5004232.558)  \n14988  POINT (-12503961.803 5004232.558)  \n\n[3748 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lat</th>\n      <th>lon</th>\n      <th>foot</th>\n      <th>lbsperday</th>\n      <th>id</th>\n      <th>TRI_source</th>\n      <th>TRI_sour_1</th>\n      <th>zagl</th>\n      <th>Chemical</th>\n      <th>Release (l</th>\n      <th>YEAR</th>\n      <th>ss_name</th>\n      <th>ss_path</th>\n      <th>ss_date</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40.745</td>\n      <td>-111.955</td>\n      <td>0.084898</td>\n      <td>9.180184</td>\n      <td>0</td>\n      <td>40.74211</td>\n      <td>-111.95802</td>\n      <td>9.4</td>\n      <td>STYRENE</td>\n      <td>39468.0</td>\n      <td>2010</td>\n      <td>201001060000_-111.95802_40.74211_9.4_foot</td>\n      <td>data/processed/stilt_output/netcdf/092520_styr...</td>\n      <td>2010-01-06</td>\n      <td>POINT (-12462773.592 4974801.670)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>40.755</td>\n      <td>-111.955</td>\n      <td>0.073125</td>\n      <td>7.907112</td>\n      <td>0</td>\n      <td>40.74211</td>\n      <td>-111.95802</td>\n      <td>9.4</td>\n      <td>STYRENE</td>\n      <td>39468.0</td>\n      <td>2010</td>\n      <td>201001060000_-111.95802_40.74211_9.4_foot</td>\n      <td>data/processed/stilt_output/netcdf/092520_styr...</td>\n      <td>2010-01-06</td>\n      <td>POINT (-12462773.592 4976271.108)</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>40.755</td>\n      <td>-111.945</td>\n      <td>0.069022</td>\n      <td>7.463464</td>\n      <td>0</td>\n      <td>40.74211</td>\n      <td>-111.95802</td>\n      <td>9.4</td>\n      <td>STYRENE</td>\n      <td>39468.0</td>\n      <td>2010</td>\n      <td>201001060000_-111.95802_40.74211_9.4_foot</td>\n      <td>data/processed/stilt_output/netcdf/092520_styr...</td>\n      <td>2010-01-06</td>\n      <td>POINT (-12461660.397 4976271.108)</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>40.765</td>\n      <td>-111.945</td>\n      <td>0.147847</td>\n      <td>15.986922</td>\n      <td>0</td>\n      <td>40.74211</td>\n      <td>-111.95802</td>\n      <td>9.4</td>\n      <td>STYRENE</td>\n      <td>39468.0</td>\n      <td>2010</td>\n      <td>201001060000_-111.95802_40.74211_9.4_foot</td>\n      <td>data/processed/stilt_output/netcdf/092520_styr...</td>\n      <td>2010-01-06</td>\n      <td>POINT (-12461660.397 4977740.767)</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>40.765</td>\n      <td>-111.935</td>\n      <td>0.003443</td>\n      <td>0.372280</td>\n      <td>0</td>\n      <td>40.74211</td>\n      <td>-111.95802</td>\n      <td>9.4</td>\n      <td>STYRENE</td>\n      <td>39468.0</td>\n      <td>2010</td>\n      <td>201001060000_-111.95802_40.74211_9.4_foot</td>\n      <td>data/processed/stilt_output/netcdf/092520_styr...</td>\n      <td>2010-01-06</td>\n      <td>POINT (-12460547.202 4977740.767)</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14972</th>\n      <td>40.945</td>\n      <td>-112.365</td>\n      <td>0.001034</td>\n      <td>0.111794</td>\n      <td>0</td>\n      <td>40.74211</td>\n      <td>-111.95802</td>\n      <td>9.4</td>\n      <td>STYRENE</td>\n      <td>39468.0</td>\n      <td>2010</td>\n      <td>201001060000_-111.95802_40.74211_9.4_foot</td>\n      <td>data/processed/stilt_output/netcdf/092520_styr...</td>\n      <td>2010-01-06</td>\n      <td>POINT (-12508414.583 5004232.558)</td>\n    </tr>\n    <tr>\n      <th>14976</th>\n      <td>40.945</td>\n      <td>-112.355</td>\n      <td>0.001060</td>\n      <td>0.114596</td>\n      <td>0</td>\n      <td>40.74211</td>\n      <td>-111.95802</td>\n      <td>9.4</td>\n      <td>STYRENE</td>\n      <td>39468.0</td>\n      <td>2010</td>\n      <td>201001060000_-111.95802_40.74211_9.4_foot</td>\n      <td>data/processed/stilt_output/netcdf/092520_styr...</td>\n      <td>2010-01-06</td>\n      <td>POINT (-12507301.388 5004232.558)</td>\n    </tr>\n    <tr>\n      <th>14980</th>\n      <td>40.945</td>\n      <td>-112.345</td>\n      <td>0.001065</td>\n      <td>0.115107</td>\n      <td>0</td>\n      <td>40.74211</td>\n      <td>-111.95802</td>\n      <td>9.4</td>\n      <td>STYRENE</td>\n      <td>39468.0</td>\n      <td>2010</td>\n      <td>201001060000_-111.95802_40.74211_9.4_foot</td>\n      <td>data/processed/stilt_output/netcdf/092520_styr...</td>\n      <td>2010-01-06</td>\n      <td>POINT (-12506188.193 5004232.558)</td>\n    </tr>\n    <tr>\n      <th>14984</th>\n      <td>40.945</td>\n      <td>-112.335</td>\n      <td>0.001046</td>\n      <td>0.113152</td>\n      <td>0</td>\n      <td>40.74211</td>\n      <td>-111.95802</td>\n      <td>9.4</td>\n      <td>STYRENE</td>\n      <td>39468.0</td>\n      <td>2010</td>\n      <td>201001060000_-111.95802_40.74211_9.4_foot</td>\n      <td>data/processed/stilt_output/netcdf/092520_styr...</td>\n      <td>2010-01-06</td>\n      <td>POINT (-12505074.998 5004232.558)</td>\n    </tr>\n    <tr>\n      <th>14988</th>\n      <td>40.945</td>\n      <td>-112.325</td>\n      <td>0.001009</td>\n      <td>0.109134</td>\n      <td>0</td>\n      <td>40.74211</td>\n      <td>-111.95802</td>\n      <td>9.4</td>\n      <td>STYRENE</td>\n      <td>39468.0</td>\n      <td>2010</td>\n      <td>201001060000_-111.95802_40.74211_9.4_foot</td>\n      <td>data/processed/stilt_output/netcdf/092520_styr...</td>\n      <td>2010-01-06</td>\n      <td>POINT (-12503961.803 5004232.558)</td>\n    </tr>\n  </tbody>\n</table>\n<p>3748 rows × 15 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "temp_20100106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}